{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook sample"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:42:21.333970Z",
     "start_time": "2025-01-02T18:42:21.324358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# make sure to install these packages before running:\n",
    "# pip install pandas\n",
    "# pip install sodapy\n",
    "# pip install python-dotenv\n",
    "# pip install kagglehub\n",
    "\n",
    "#Read data\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Extract & Transform\n",
    "import kagglehub\n",
    "import ast\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "# Normalize locations\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderQuotaExceeded\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "#Load\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ],
   "id": "ae70d15e34a5ea9a",
   "outputs": [],
   "execution_count": 248
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:42:23.358206Z",
     "start_time": "2025-01-02T18:42:23.346874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the secrets\n",
    "app_token = os.getenv(\"APP_TOKEN\")\n",
    "username = os.getenv(\"OPEN_DATA_NYC_USERNAME\")\n",
    "password = os.getenv(\"OPEN_DATA_NYC_PASSWORD\")"
   ],
   "id": "6f92976e28f579d2",
   "outputs": [],
   "execution_count": 249
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:21.848893Z",
     "start_time": "2025-01-03T00:26:21.841063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_restaurant_data(app_token, username, password, dataset_id=\"pitm-atqc\", limit=1000):\n",
    "    \"\"\"\n",
    "    Fetch restaurant data from the NYC Open Data API.\n",
    "\n",
    "    Parameters:\n",
    "        app_token (str): Your application token for the API.\n",
    "        username (str): Your username for the API (email).\n",
    "        password (str): Your password for the API.\n",
    "        dataset_id (str): The dataset identifier in Socrata.\n",
    "        limit (int): The maximum number of results to fetch (default is 1000).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas DataFrame containing the restaurant data.\n",
    "    \"\"\"\n",
    "    # Initialize the Socrata client\n",
    "    client = Socrata(\"data.cityofnewyork.us\", app_token, username=username, password=password)\n",
    "\n",
    "    # Fetch data\n",
    "    results = client.get(dataset_id, limit=limit)\n",
    "\n",
    "    # Convert results to a pandas DataFrame\n",
    "    df_restaurants = pd.DataFrame.from_records(results)\n",
    "\n",
    "    return df_restaurants\n",
    "\n",
    "# Example usage:\n",
    "# app_token = \"your_app_token\"\n",
    "# username = \"your_username\"\n",
    "# password = \"your_password\"\n",
    "#df_restaurants = fetch_restaurant_data(app_token, username, password)\n",
    "# print(df.head())\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 419
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:25.059253Z",
     "start_time": "2025-01-03T00:26:25.046035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_selected_sheets(file_path, sheet_names, header_row_mapping):\n",
    "    \"\"\"\n",
    "    Parse selected worksheets from an XML-based Excel workbook.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the XML file.\n",
    "        sheet_names (list): List of worksheet names to parse.\n",
    "        header_row_mapping (dict): A mapping of sheet names to header row indices.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of pandas DataFrames corresponding to the selected sheets.\n",
    "    \"\"\"\n",
    "    def extract_row_data(cells, expected_columns):\n",
    "        \"\"\"\n",
    "        Helper function to extract row data and ensure it matches the number of headers.\n",
    "        \"\"\"\n",
    "        row_data = []\n",
    "        for i in range(expected_columns):\n",
    "            try:\n",
    "                cell = cells[i].find(\".//ss:Data\", ns)\n",
    "                row_data.append(cell.text.strip() if cell is not None else None)\n",
    "            except IndexError:\n",
    "                row_data.append(None)  # Append None if the column is missing\n",
    "        return row_data\n",
    "\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Namespace dictionary for handling XML namespaces\n",
    "    ns = {'ss': 'urn:schemas-microsoft-com:office:spreadsheet'}\n",
    "\n",
    "    # Retrieve all worksheets\n",
    "    worksheets = root.findall(\".//ss:Worksheet\", ns)\n",
    "\n",
    "    # List to store DataFrames for selected sheets\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through each worksheet\n",
    "    for sheet in worksheets:\n",
    "        sheet_name = sheet.attrib.get(f\"{{{ns['ss']}}}Name\")  # Get the sheet name\n",
    "        if sheet_name not in sheet_names:\n",
    "            continue  # Skip sheets that are not in the specified list\n",
    "\n",
    "        rows = sheet.findall(\".//ss:Row\", ns)  # Find all rows in the sheet\n",
    "\n",
    "        if not rows:\n",
    "            print(f\"Sheet '{sheet_name}' is empty. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Determine the header row index (default to 0 if not specified)\n",
    "        header_row_index = header_row_mapping.get(sheet_name, 0)\n",
    "        if header_row_index >= len(rows):\n",
    "            print(f\"Invalid header row index for sheet: {sheet_name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Extract headers from the specified row\n",
    "        header_row = rows[header_row_index]\n",
    "        headers = []\n",
    "        for cell in header_row.findall(\".//ss:Cell\", ns):\n",
    "            data = cell.find(\".//ss:Data\", ns)\n",
    "            headers.append(data.text.strip() if data is not None else None)\n",
    "        expected_columns = len(headers)\n",
    "\n",
    "        # Extract data (skip up to the header row)\n",
    "        data = []\n",
    "        for row in rows[header_row_index + 1:]:  # Start after the header row\n",
    "            cells = row.findall(\".//ss:Cell\", ns)\n",
    "            row_data = extract_row_data(cells, expected_columns)\n",
    "            data.append(row_data)\n",
    "\n",
    "        # Create a DataFrame for the sheet\n",
    "        df = pd.DataFrame(data, columns=headers)\n",
    "        dataframes.append(df)  # Add the DataFrame to the list\n",
    "\n",
    "        print(f\"Processed sheet: {sheet_name} with {len(df)} rows\")\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "def fetch_fliming_locations_data(xml_file_path):\n",
    "    \"\"\"\n",
    "    Fetch the \"Full Map List\" worksheet as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        xml_file_path (str): Path to the XML file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas DataFrame containing data from the \"Full Map List\" worksheet.\n",
    "    \"\"\"\n",
    "    # Sheet names of interest\n",
    "    selected_sheets = ['Full Map List']\n",
    "\n",
    "    # Header row mapping for each sheet\n",
    "    header_row_mapping = {\n",
    "        'Full Map List': 1\n",
    "    }\n",
    "\n",
    "    # Parse the selected sheets\n",
    "    dfs = parse_selected_sheets(xml_file_path, selected_sheets, header_row_mapping)\n",
    "    df_filming_locations = dfs[0]  # Extract the DataFrame for the 'Full Map List' sheet\n",
    "\n",
    "    return df_filming_locations"
   ],
   "id": "abac52feade3d8d0",
   "outputs": [],
   "execution_count": 420
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:30.333793Z",
     "start_time": "2025-01-03T00:26:30.328309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_movies_data(kaggle_dataset, filename=\"25k IMDb movie Dataset.csv\"):\n",
    "    \"\"\"\n",
    "    Download the latest version of a Kaggle dataset and return the movies DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        kaggle_dataset (str): The Kaggle dataset identifier (e.g., \"utsh0dey/25k-movie-dataset\").\n",
    "        filename (str): The name of the CSV file to load (default is \"25k IMDb movie Dataset.csv\").\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas DataFrame containing the movies data.\n",
    "    \"\"\"\n",
    "    # Download the latest version of the dataset\n",
    "    path = kagglehub.dataset_download(kaggle_dataset)\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    # Construct the full path to the CSV file\n",
    "    csv_path = f\"{path}/{filename}\"\n",
    "\n",
    "    # Load the dataset into a pandas DataFrame\n",
    "    df_movies = pd.read_csv(csv_path)\n",
    "\n",
    "    return df_movies"
   ],
   "id": "d3ba7c57285e02db",
   "outputs": [],
   "execution_count": 421
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:40.376505Z",
     "start_time": "2025-01-03T00:26:34.193332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_restaurants_raw = fetch_restaurant_data(app_token, username, password)\n",
    "df_restaurants_raw.head()"
   ],
   "id": "b94ccaff33c0604",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  objectid                                globalid seating_interest_sidewalk  \\\n",
       "0      100    c4b3155b-31a0-4e95-846f-fce09f245437                  sidewalk   \n",
       "1     1000    753495d8-4429-43e5-85a3-dcf6230ef749                      both   \n",
       "2    10000  {3842B5C5-EF04-41A4-8216-D6EA627DCE5E}               openstreets   \n",
       "3    10001  {C212A0FC-C115-4425-8F95-931B12C5F86A}               openstreets   \n",
       "4    10002  {DA48265D-7730-416F-8E1C-EBC8C8ACE2C2}               openstreets   \n",
       "\n",
       "                     restaurant_name                    legal_business_name  \\\n",
       "0  Pomp and Circumstance Hospitality  Pomp and Circumstance Hospitality LLC   \n",
       "1                          Charm Kao                    193 Schemerhorn INC   \n",
       "2                   SAKE BAR HAGI 46                    HAMA NEW YORK, INC.   \n",
       "3                        Yum yum too                            Boythaicorp   \n",
       "4                  Xochil Pizza Corp                      Xochil Pizza Corp   \n",
       "\n",
       "                   doing_business_as_dba bulding_number            street  \\\n",
       "0  Pomp and Circumstance Hospitality LLC            577    Lorimer Street   \n",
       "1                              Charm Kao            193  Schermerhorn St.   \n",
       "2                       SAKE BAR HAGI 46            358    W. 46TH STREET   \n",
       "3                            Boythaicorp            662              9ave   \n",
       "4                      Xochil Pizza Corp           4632        5th Avenue   \n",
       "\n",
       "     borough    zip  ... community_board council_district census_tract  \\\n",
       "0   Brooklyn  11211  ...               1               34          501   \n",
       "1   Brooklyn  11201  ...               2               33           37   \n",
       "2  Manhattan  10036  ...               4                3          121   \n",
       "3  Manhattan  10036  ...               4                3          127   \n",
       "4   Brooklyn  11220  ...               7               38           80   \n",
       "\n",
       "       bin         bbl                                               nta  \\\n",
       "0  3068653  3027560028                                 East Williamsburg   \n",
       "1  3000493  3001640041  DUMBO-Vinegar Hill-Downtown Brooklyn-Boerum Hill   \n",
       "2  1025025  1010360057                                           Clinton   \n",
       "3  1025038  1010370001                                           Clinton   \n",
       "4      NaN         NaN                                  Sunset Park West   \n",
       "\n",
       "  roadway_dimensions_length roadway_dimensions_width roadway_dimensions_area  \\\n",
       "0                       NaN                      NaN                     NaN   \n",
       "1                        24                        8                     192   \n",
       "2                       NaN                      NaN                     NaN   \n",
       "3                       NaN                      NaN                     NaN   \n",
       "4                       NaN                      NaN                     NaN   \n",
       "\n",
       "  landmarkdistrict_terms  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>globalid</th>\n",
       "      <th>seating_interest_sidewalk</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>legal_business_name</th>\n",
       "      <th>doing_business_as_dba</th>\n",
       "      <th>bulding_number</th>\n",
       "      <th>street</th>\n",
       "      <th>borough</th>\n",
       "      <th>zip</th>\n",
       "      <th>...</th>\n",
       "      <th>community_board</th>\n",
       "      <th>council_district</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>bin</th>\n",
       "      <th>bbl</th>\n",
       "      <th>nta</th>\n",
       "      <th>roadway_dimensions_length</th>\n",
       "      <th>roadway_dimensions_width</th>\n",
       "      <th>roadway_dimensions_area</th>\n",
       "      <th>landmarkdistrict_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>c4b3155b-31a0-4e95-846f-fce09f245437</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>Pomp and Circumstance Hospitality</td>\n",
       "      <td>Pomp and Circumstance Hospitality LLC</td>\n",
       "      <td>Pomp and Circumstance Hospitality LLC</td>\n",
       "      <td>577</td>\n",
       "      <td>Lorimer Street</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11211</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>501</td>\n",
       "      <td>3068653</td>\n",
       "      <td>3027560028</td>\n",
       "      <td>East Williamsburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>753495d8-4429-43e5-85a3-dcf6230ef749</td>\n",
       "      <td>both</td>\n",
       "      <td>Charm Kao</td>\n",
       "      <td>193 Schemerhorn INC</td>\n",
       "      <td>Charm Kao</td>\n",
       "      <td>193</td>\n",
       "      <td>Schermerhorn St.</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>3000493</td>\n",
       "      <td>3001640041</td>\n",
       "      <td>DUMBO-Vinegar Hill-Downtown Brooklyn-Boerum Hill</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>192</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>{3842B5C5-EF04-41A4-8216-D6EA627DCE5E}</td>\n",
       "      <td>openstreets</td>\n",
       "      <td>SAKE BAR HAGI 46</td>\n",
       "      <td>HAMA NEW YORK, INC.</td>\n",
       "      <td>SAKE BAR HAGI 46</td>\n",
       "      <td>358</td>\n",
       "      <td>W. 46TH STREET</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10036</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>1025025</td>\n",
       "      <td>1010360057</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>{C212A0FC-C115-4425-8F95-931B12C5F86A}</td>\n",
       "      <td>openstreets</td>\n",
       "      <td>Yum yum too</td>\n",
       "      <td>Boythaicorp</td>\n",
       "      <td>Boythaicorp</td>\n",
       "      <td>662</td>\n",
       "      <td>9ave</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10036</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>1025038</td>\n",
       "      <td>1010370001</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002</td>\n",
       "      <td>{DA48265D-7730-416F-8E1C-EBC8C8ACE2C2}</td>\n",
       "      <td>openstreets</td>\n",
       "      <td>Xochil Pizza Corp</td>\n",
       "      <td>Xochil Pizza Corp</td>\n",
       "      <td>Xochil Pizza Corp</td>\n",
       "      <td>4632</td>\n",
       "      <td>5th Avenue</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11220</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunset Park West</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 422
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:40.498881Z",
     "start_time": "2025-01-03T00:26:40.424520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "xml_file_path = \"./datasets/Interactive_Map_Data.xml\"\n",
    "df_fl_raw = fetch_fliming_locations_data(xml_file_path)"
   ],
   "id": "ec165c068565e82b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sheet: Full Map List with 233 rows\n"
     ]
    }
   ],
   "execution_count": 423
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:41.590831Z",
     "start_time": "2025-01-03T00:26:40.767454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "kaggle_dataset = \"utsh0dey/25k-movie-dataset\"\n",
    "df_movies_raw = fetch_movies_data(kaggle_dataset)"
   ],
   "id": "beee16c73f9b021b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\huniv\\.cache\\kagglehub\\datasets\\utsh0dey\\25k-movie-dataset\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 424
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:41.680287Z",
     "start_time": "2025-01-03T00:26:41.675481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_movie_id(df, path_column='path', new_column='imdb_id'):\n",
    "    \"\"\"\n",
    "    Extract the unique movie ID from the 'path' field and add it as a new column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing the 'path' column.\n",
    "        path_column (str): The name of the column containing the path (default: 'path').\n",
    "        new_column (str): The name of the new column for the extracted movie ID (default: 'movie_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with the extracted movie ID column.\n",
    "    \"\"\"\n",
    "    # Check if the path column exists\n",
    "    if path_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{path_column}' not found in the DataFrame.\")\n",
    "\n",
    "    # Use regex to extract the movie ID from the path\n",
    "    df[new_column] = df[path_column].str.extract(r'/title/(tt\\d+)/')\n",
    "\n",
    "    return df"
   ],
   "id": "dfbdad920fc274e",
   "outputs": [],
   "execution_count": 425
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:43.014686Z",
     "start_time": "2025-01-03T00:26:43.008620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_year(df, column_name='year'):\n",
    "    \"\"\"\n",
    "    Extract four-digit year from a given column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the year column.\n",
    "        column_name (str): The name of the column to process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with the year column cleaned.\n",
    "    \"\"\"\n",
    "    # Extract the four-digit year using regex\n",
    "    df[column_name] = df[column_name].str.extract(r'(\\b\\d{4}\\b)', expand=False)\n",
    "\n",
    "    # Replace any NaN values with \"null\"\n",
    "    #df[column_name] = df[column_name].astype('object').fillna(None)\n",
    "    #df[column_name] = df[column_name].astype('Int64')  # Pandas nullable integer type\n",
    "\n",
    "    return df"
   ],
   "id": "4bac892ef18bae06",
   "outputs": [],
   "execution_count": 426
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:26:45.353085Z",
     "start_time": "2025-01-03T00:26:45.332936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_column(df, old_column_name, new_column_name):\n",
    "    \"\"\"\n",
    "    Rename a column and convert its values from strings to Python lists.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the column.\n",
    "        old_column_name (str): The current name of the column.\n",
    "        new_column_name (str): The new name for the column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with the renamed and properly formatted column.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the old_column_name is not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    if old_column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{old_column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # Rename the column\n",
    "    df = df.rename(columns={old_column_name: new_column_name})\n",
    "\n",
    "    # Convert column values from string to list\n",
    "    df[new_column_name] = df[new_column_name].apply(ast.literal_eval)  # Safely convert string to list\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_lookup_table(df, column_name, id_column_name, value_column_name):\n",
    "    \"\"\"\n",
    "    Create a lookup table with unique values and their IDs from a column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the column.\n",
    "        column_name (str): The name of the column to extract unique values from.\n",
    "        id_column_name (str): The name of the ID column in the lookup table.\n",
    "        value_column_name (str): The name of the value column in the lookup table.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A lookup table with unique values and their IDs.\n",
    "    \"\"\"\n",
    "    # Extract unique values and assign IDs\n",
    "    unique_values = set(value for values_list in df[column_name] for value in values_list)\n",
    "    lookup_table = pd.DataFrame({value_column_name: sorted(unique_values)})\n",
    "    lookup_table[id_column_name] = lookup_table.index + 1  # Assign unique IDs starting from 1\n",
    "\n",
    "    return lookup_table\n",
    "\n",
    "\n",
    "def create_link_table(df, lookup_table, column_name, id_column_name, movie_id_column, value_column_name):\n",
    "    \"\"\"\n",
    "    Create a link table connecting movies to values (e.g., genres, actors) by their IDs.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The movies DataFrame.\n",
    "        lookup_table (pd.DataFrame): The lookup table with unique values and their IDs.\n",
    "        column_name (str): The name of the column in the movies DataFrame to link.\n",
    "        id_column_name (str): The name of the ID column in the link table.\n",
    "        movie_id_column (str): The name of the unique movie identifier column in the movies DataFrame.\n",
    "        value_column_name (str): The name of the value column in the lookup table.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A link table connecting movies (movie_id) to values (e.g., genres, actors) by their IDs.\n",
    "    \"\"\"\n",
    "    # Explode the column into separate rows\n",
    "    df_expanded = df.explode(column_name)\n",
    "\n",
    "    # Map values to their IDs using the lookup table\n",
    "    link_table = (df_expanded[[movie_id_column, column_name]]\n",
    "                  .merge(lookup_table, left_on=column_name, right_on=value_column_name)\n",
    "                  .rename(columns={id_column_name: id_column_name})\n",
    "                  )\n",
    "\n",
    "    # Drop unnecessary columns and return the link table\n",
    "    return link_table[[movie_id_column, id_column_name]]\n",
    "\n",
    "def clean_and_reorder_movies(df):\n",
    "    \"\"\"\n",
    "    Clean and reorder the movies DataFrame by renaming, dropping, and reordering columns.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input movies DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned and reordered movies DataFrame.\n",
    "    \"\"\"\n",
    "    # Rename columns, drop unuseful columns, make lowercase, and reorder\n",
    "    df = (\n",
    "        df.rename(columns={\n",
    "            'movie title': 'title',\n",
    "            'User Rating': 'nb_users_ratings',\n",
    "            'Rating': 'rating'\n",
    "        })\n",
    "        .drop(columns=['Run Time', 'genres', 'Plot Kyeword', 'actors', 'path'])\n",
    "        .pipe(lambda x: x.set_axis(x.columns.str.lower(), axis=1))\n",
    "        .loc[:, ['imdb_id', 'title', 'year', 'director', 'writer', 'overview', 'rating', 'nb_users_ratings']]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def process_movie_data(df_movies):\n",
    "    \"\"\"\n",
    "    Process the movie dataset through the entire data pipeline:\n",
    "    1. Prepare and clean the genres column.\n",
    "    2. Extract the 4-digit year.\n",
    "    3. Create the Genres lookup table.\n",
    "    4. Create the Movies_Genres link table.\n",
    "    5. Prepare and clean the actors column.\n",
    "    6. Create the Actors lookup table.\n",
    "    7. Create the Movies_Actors link table.\n",
    "    8. Clean and reorder the movies DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df_movies (pd.DataFrame): The raw movies DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - df_movies (pd.DataFrame): Cleaned and reordered movies DataFrame.\n",
    "            - df_genres (pd.DataFrame): Genres lookup table.\n",
    "            - df_movies_genres (pd.DataFrame): Movies_Genres link table.\n",
    "            - df_actors (pd.DataFrame): Actors lookup table.\n",
    "            - df_movies_actors (pd.DataFrame): Movies_Actors link table.\n",
    "    \"\"\"\n",
    "    df_movies = extract_movie_id(df_movies, path_column='path', new_column='imdb_id')\n",
    "    \n",
    "    # Step 1: Prepare the genres column\n",
    "    df_movies = prepare_column(df_movies, old_column_name='Generes', new_column_name='genres')\n",
    "\n",
    "    # Step 2: Extract 4-digit year\n",
    "    df_movies = extract_year(df_movies, column_name='year')\n",
    "\n",
    "    # Step 3: Create the Genres lookup table\n",
    "    df_genres = create_lookup_table(df_movies, column_name='genres', id_column_name='genre_id', value_column_name='genre')\n",
    "\n",
    "    # Step 4: Create the Movies_Genres link table\n",
    "    df_movies_genres = create_link_table(\n",
    "        df_movies,\n",
    "        df_genres,\n",
    "        column_name='genres',\n",
    "        id_column_name='genre_id',\n",
    "        movie_id_column='imdb_id',\n",
    "        value_column_name='genre'\n",
    "    )\n",
    "\n",
    "    # Step 5: Prepare the actors column\n",
    "    df_movies = prepare_column(df_movies, old_column_name='Top 5 Casts', new_column_name='actors')\n",
    "\n",
    "    # Step 6: Create the Actors lookup table\n",
    "    df_actors = create_lookup_table(\n",
    "        df_movies, column_name='actors', id_column_name='actor_id', value_column_name='actor_name'\n",
    "    )\n",
    "\n",
    "    # Step 7: Create the Movies_Actors link table\n",
    "    df_movies_actors = create_link_table(\n",
    "        df_movies,\n",
    "        df_actors,\n",
    "        column_name='actors',\n",
    "        id_column_name='actor_id',\n",
    "        movie_id_column='imdb_id',\n",
    "        value_column_name='actor_name'\n",
    "    )\n",
    "\n",
    "    # Step 8: Clean and reorder the movies DataFrame\n",
    "    df_movies = clean_and_reorder_movies(df_movies)\n",
    "\n",
    "    # Replace \"no-rating\" with None (equivalent to NULL in databases)\n",
    "    df_movies['rating'] = df_movies['rating'].replace('no-rating', None)\n",
    "\n",
    "    return df_movies, df_genres, df_movies_genres, df_actors, df_movies_actors\n",
    "\n"
   ],
   "id": "6b07b1769834e4ff",
   "outputs": [],
   "execution_count": 427
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:47:55.162155Z",
     "start_time": "2025-01-03T00:47:54.150191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_movies = df_movies_raw\n",
    "# Assuming the required functions are already implemented:\n",
    "# - prepare_column\n",
    "# - extract_year\n",
    "# - create_lookup_table\n",
    "# - create_link_table\n",
    "# - clean_and_reorder_movies\n",
    "\n",
    "# Process the movie data\n",
    "df_movies_cleaned, df_genres, df_movies_genres, df_actors, df_movies_actors = process_movie_data(df_movies)"
   ],
   "id": "dc51c65a0f1714ed",
   "outputs": [],
   "execution_count": 496
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:48:40.545159Z",
     "start_time": "2025-01-03T00:48:40.540863Z"
    }
   },
   "cell_type": "code",
   "source": "df_movies_actors.shape",
   "id": "40b25abbcc732aae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113217, 2)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 501
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:48:27.471042Z",
     "start_time": "2025-01-03T00:48:27.445878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df_movies_actors = df_movies_actors.drop_duplicates(subset=['actor_id', 'imdb_id'])"
   ],
   "id": "a8c596506390704",
   "outputs": [],
   "execution_count": 498
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:31:28.442906Z",
     "start_time": "2025-01-03T00:31:28.431335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_location_text(location_text):\n",
    "    \"\"\"\n",
    "    Clean the Location Display Text field by removing HTML tags, extra spaces, and newlines.\n",
    "\n",
    "    Parameters:\n",
    "        location_text (str): The raw location text.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned location text.\n",
    "    \"\"\"\n",
    "    if not isinstance(location_text, str):\n",
    "        return location_text  # Return as is if not a string\n",
    "\n",
    "    # Remove HTML tags (e.g., <br>)\n",
    "    cleaned_text = re.sub(r'<[^>]*>', ' ', location_text)  # Match any HTML-like tag\n",
    "\n",
    "    # Replace newlines and excessive whitespace with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "\n",
    "    # Strip leading and trailing whitespace\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def process_filming_locations(df):\n",
    "    \"\"\"\n",
    "   Process the filming locations dataset, including cleaning the location text.\n",
    "\n",
    "   Parameters:\n",
    "       df (pd.DataFrame): The raw filming locations DataFrame.\n",
    "\n",
    "   Returns:\n",
    "       tuple: A tuple containing two DataFrames:\n",
    "           - df_filming_locations: Contains metadata and IMDB details.\n",
    "           - df_filming_locations_movies: Contains location details.\n",
    "   \"\"\"\n",
    "    # Step 1: Add a unique identifier for each row\n",
    "    df['location_id'] = range(1, len(df) + 1) #[str(uuid.uuid4()) for _ in range(len(df))]\n",
    "    \n",
    "    # Step 2: Rename 'IMDB LINK' to 'imdb_id' and extract the ID from the URL\n",
    "    df = df.rename(columns={'IMDB LINK': 'imdb_id'})\n",
    "    df['imdb_id'] = df['imdb_id'].apply(\n",
    "        lambda x: re.search(r'tt\\d+', x).group() if isinstance(x, str) and re.search(r'tt\\d+', x) else None\n",
    "    )\n",
    "    \n",
    "    # Step 3: Extract the Director/Filmmaker ID from the 'Director/Filmmaker IMDB Link' column\n",
    "    df['director_imdb_id'] = df['Director/Filmmaker IMDB Link'].apply(\n",
    "        lambda x: re.search(r'nm\\d+', x).group() if isinstance(x, str) and re.search(r'nm\\d+', x) else None\n",
    "    )\n",
    "    \n",
    "    # Step 4: Clean the Location Display Text field\n",
    "    df['Location Display Text'] = df['Location Display Text'].apply(clean_location_text)\n",
    "    \n",
    "    # Step 4: Clean the Location Display Text field\n",
    "    df['Client or book location indicator'] = df['Client or book location indicator'].apply(clean_location_text)\n",
    "\n",
    "\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.rename(columns={\n",
    "        'movie title': 'title',\n",
    "        'location display text': 'address',\n",
    "        'client or book location indicator': 'address_indicator'\n",
    "    })\n",
    "    \n",
    "    # Step 5: Create df_filming_locations\n",
    "    #df_filming_locations = df[['filming_locations_id', 'Director/Filmmaker Name', 'director_imdb_id']].copy()\n",
    "    df_locations = df[['location_id', 'address', 'address_indicator', 'latitude',\n",
    "                               'longitude', 'borough', 'neighborhood']].copy()\n",
    "    \n",
    "    # Step 6: Create df_filming_locations_movies\n",
    "    df_locations_movies = df[['location_id', 'imdb_id']].copy()\n",
    "    \n",
    "    return df_locations, df_locations_movies"
   ],
   "id": "6ab6f28471b4f2ea",
   "outputs": [],
   "execution_count": 455
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:31:32.438860Z",
     "start_time": "2025-01-03T00:31:32.429159Z"
    }
   },
   "cell_type": "code",
   "source": "df_locations_m, df_locations_movies = process_filming_locations(df_fl_raw)",
   "id": "119aa9102f359c51",
   "outputs": [],
   "execution_count": 456
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:31:34.331914Z",
     "start_time": "2025-01-03T00:31:34.325077Z"
    }
   },
   "cell_type": "code",
   "source": "df_locations_movies.tail()",
   "id": "c1d5d28603687e00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     location_id    imdb_id\n",
       "228          229  tt0096463\n",
       "229          230  tt0061209\n",
       "230          231  tt0061209\n",
       "231          232  tt0128853\n",
       "232          233  tt0128853"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>tt0096463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>230</td>\n",
       "      <td>tt0061209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>231</td>\n",
       "      <td>tt0061209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>232</td>\n",
       "      <td>tt0128853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>233</td>\n",
       "      <td>tt0128853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 457
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:31:53.328265Z",
     "start_time": "2025-01-03T00:31:53.321753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_restaurant_data(df):\n",
    "    \"\"\"\n",
    "    Process the restaurant dataset by cleaning, splitting into relevant DataFrames,\n",
    "    adding unique identifiers, and transforming the landmarkdistrict_terms column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original restaurant DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (df_restaurants, df_locations, df_restaurants_locations)\n",
    "    \"\"\"\n",
    "    # Step 1: Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "        'sidewalk_dimensions_length', 'sidewalk_dimensions_width', 'sidewalk_dimensions_area',\n",
    "        'approved_for_sidewalk_seating', 'approved_for_roadway_seating', 'qualify_alcohol',\n",
    "        'sla_serial_number', 'sla_license_type', 'landmark_district_or_building',\n",
    "        'healthcompliance_terms', 'time_of_submission', 'community_board', 'council_district',\n",
    "        'census_tract', 'bin', 'bbl', 'roadway_dimensions_length', 'roadway_dimensions_width',\n",
    "        'roadway_dimensions_area', 'globalid', 'objectid', 'food_service_establishment',\n",
    "    ]\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')  # Safeguard against missing columns\n",
    "\n",
    "    # Step 2: Add unique identifiers\n",
    "    df['restaurant_id'] = range(1, len(df) + 1)\n",
    "    df['location_id'] = range(233, 233 + len(df)) #[str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "    # Step 3: Transform the landmarkdistrict_terms column to boolean\n",
    "    df['landmarkdistrict_terms'] = df['landmarkdistrict_terms'].fillna('false')  # Replace NaN with 'false'\n",
    "    df['landmarkdistrict_terms'] = df['landmarkdistrict_terms'].str.lower().map({'yes': True, 'false': False})\n",
    "\n",
    "    # Fix typo\n",
    "    df = df.rename(columns={\n",
    "        'bulding_number': 'building_number', \n",
    "    })\n",
    "\n",
    "    # Step 4: Create df_restaurants\n",
    "    df_restaurants = df[['restaurant_id', 'location_id', 'restaurant_name', 'legal_business_name', 'doing_business_as_dba', 'seating_interest_sidewalk', 'landmarkdistrict_terms']].copy()\n",
    "\n",
    "    # Step 5: Create df_locations\n",
    "    df_locations = df[['location_id', 'building_number', 'street', 'borough', 'zip',\n",
    "                       'business_address', 'latitude', 'longitude', 'nta']].copy()\n",
    "\n",
    "    return df_restaurants, df_locations\n"
   ],
   "id": "613fe649100231a6",
   "outputs": [],
   "execution_count": 459
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:31:56.523833Z",
     "start_time": "2025-01-03T00:31:56.508399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_restaurants, df_locations_r = process_restaurant_data(df_restaurants_raw)\n",
    "\n",
    "# Display the results\n",
    "df_restaurants"
   ],
   "id": "23e7a76c77123834",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     restaurant_id  location_id                    restaurant_name  \\\n",
       "0                1          233  Pomp and Circumstance Hospitality   \n",
       "1                2          234                          Charm Kao   \n",
       "2                3          235                   SAKE BAR HAGI 46   \n",
       "3                4          236                        Yum yum too   \n",
       "4                5          237                  Xochil Pizza Corp   \n",
       "..             ...          ...                                ...   \n",
       "995            996         1228                     DONT TELL MAMA   \n",
       "996            997         1229                     OLD MAN HUSTLE   \n",
       "997            998         1230  Tsurutontan Udon Noodle Brasserie   \n",
       "998            999         1231                           PHO PLUS   \n",
       "999           1000         1232                NEW YORK BURGER CO.   \n",
       "\n",
       "                       legal_business_name  \\\n",
       "0    Pomp and Circumstance Hospitality LLC   \n",
       "1                      193 Schemerhorn INC   \n",
       "2                      HAMA NEW YORK, INC.   \n",
       "3                              Boythaicorp   \n",
       "4                        Xochil Pizza Corp   \n",
       "..                                     ...   \n",
       "995                            DTM PB CORP   \n",
       "996                        EDMANHUSTLE LLC   \n",
       "997       Dining Innovation New York, Inc.   \n",
       "998                           PHO PLUS INC   \n",
       "999         NEW YORK BURGER 10TH AVE, INC.   \n",
       "\n",
       "                     doing_business_as_dba seating_interest_sidewalk  \\\n",
       "0    Pomp and Circumstance Hospitality LLC                  sidewalk   \n",
       "1                                Charm Kao                      both   \n",
       "2                         SAKE BAR HAGI 46               openstreets   \n",
       "3                              Boythaicorp               openstreets   \n",
       "4                        Xochil Pizza Corp               openstreets   \n",
       "..                                     ...                       ...   \n",
       "995                         DONT TELL MAMA                      both   \n",
       "996                         OLD MAN HUSTLE                      both   \n",
       "997      Tsurutontan Udon Noodle Brasserie                  sidewalk   \n",
       "998                               PHO PLUS                      both   \n",
       "999                    NEW YORK BURGER CO.                   roadway   \n",
       "\n",
       "     landmarkdistrict_terms  \n",
       "0                     False  \n",
       "1                     False  \n",
       "2                     False  \n",
       "3                     False  \n",
       "4                     False  \n",
       "..                      ...  \n",
       "995                   False  \n",
       "996                   False  \n",
       "997                   False  \n",
       "998                   False  \n",
       "999                    True  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>legal_business_name</th>\n",
       "      <th>doing_business_as_dba</th>\n",
       "      <th>seating_interest_sidewalk</th>\n",
       "      <th>landmarkdistrict_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>Pomp and Circumstance Hospitality</td>\n",
       "      <td>Pomp and Circumstance Hospitality LLC</td>\n",
       "      <td>Pomp and Circumstance Hospitality LLC</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>234</td>\n",
       "      <td>Charm Kao</td>\n",
       "      <td>193 Schemerhorn INC</td>\n",
       "      <td>Charm Kao</td>\n",
       "      <td>both</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>SAKE BAR HAGI 46</td>\n",
       "      <td>HAMA NEW YORK, INC.</td>\n",
       "      <td>SAKE BAR HAGI 46</td>\n",
       "      <td>openstreets</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>236</td>\n",
       "      <td>Yum yum too</td>\n",
       "      <td>Boythaicorp</td>\n",
       "      <td>Boythaicorp</td>\n",
       "      <td>openstreets</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>237</td>\n",
       "      <td>Xochil Pizza Corp</td>\n",
       "      <td>Xochil Pizza Corp</td>\n",
       "      <td>Xochil Pizza Corp</td>\n",
       "      <td>openstreets</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>1228</td>\n",
       "      <td>DONT TELL MAMA</td>\n",
       "      <td>DTM PB CORP</td>\n",
       "      <td>DONT TELL MAMA</td>\n",
       "      <td>both</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>1229</td>\n",
       "      <td>OLD MAN HUSTLE</td>\n",
       "      <td>EDMANHUSTLE LLC</td>\n",
       "      <td>OLD MAN HUSTLE</td>\n",
       "      <td>both</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>1230</td>\n",
       "      <td>Tsurutontan Udon Noodle Brasserie</td>\n",
       "      <td>Dining Innovation New York, Inc.</td>\n",
       "      <td>Tsurutontan Udon Noodle Brasserie</td>\n",
       "      <td>sidewalk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>1231</td>\n",
       "      <td>PHO PLUS</td>\n",
       "      <td>PHO PLUS INC</td>\n",
       "      <td>PHO PLUS</td>\n",
       "      <td>both</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>1232</td>\n",
       "      <td>NEW YORK BURGER CO.</td>\n",
       "      <td>NEW YORK BURGER 10TH AVE, INC.</td>\n",
       "      <td>NEW YORK BURGER CO.</td>\n",
       "      <td>roadway</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 460
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:07.268285Z",
     "start_time": "2025-01-03T00:32:07.260001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_locations(df_filming_locations, df_restaurant_locations):\n",
    "    \"\"\"\n",
    "    Merge two location dataframes (filming and restaurants) into a unified locations dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        df_filming_locations (pd.DataFrame): DataFrame containing filming location data.\n",
    "        df_restaurant_locations (pd.DataFrame): DataFrame containing restaurant location data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A unified locations DataFrame.\n",
    "    \"\"\"\n",
    "    # Standardize column names\n",
    "    df_filming_locations = df_filming_locations.rename(columns={\n",
    "        'neighborhood': 'neighborhood_or_nta'\n",
    "    })\n",
    "\n",
    "    df_restaurant_locations = df_restaurant_locations.rename(columns={\n",
    "        'nta': 'neighborhood_or_nta',\n",
    "        'business_address': 'address'\n",
    "    })\n",
    "\n",
    "    # Add source type column\n",
    "    df_filming_locations['source_type'] = 'filming'\n",
    "    df_restaurant_locations['source_type'] = 'restaurant'\n",
    "\n",
    "    # Select relevant columns\n",
    "    df_filming_locations = df_filming_locations[[\n",
    "        'location_id', 'address', 'address_indicator', 'borough', 'neighborhood_or_nta', 'latitude', 'longitude', 'source_type'\n",
    "    ]]\n",
    "    df_restaurant_locations = df_restaurant_locations[[\n",
    "        'location_id', 'building_number', 'street', 'zip', 'borough', 'address', 'neighborhood_or_nta', 'latitude', 'longitude', 'source_type'\n",
    "    ]]\n",
    "\n",
    "    # Concatenate the two dataframes\n",
    "    df_locations = pd.concat([df_filming_locations, df_restaurant_locations], ignore_index=True).loc[:, ['location_id', 'building_number', 'street', 'zip', 'borough', 'address', 'address_indicator', 'neighborhood_or_nta', 'latitude', 'longitude', 'source_type']]\n",
    "\n",
    "    # Deduplicate locations based on lat/lon\n",
    "    #df_locations = df_locations.drop_duplicates(subset=['lat', 'lon']).reset_index(drop=True)\n",
    "\n",
    "    return df_locations"
   ],
   "id": "64b7e7f47a45bbe5",
   "outputs": [],
   "execution_count": 461
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:12.767118Z",
     "start_time": "2025-01-03T00:32:12.758462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "df_unified_locations = merge_locations(df_locations_m, df_locations_r)"
   ],
   "id": "e279cb433dd73263",
   "outputs": [],
   "execution_count": 462
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:15.633390Z",
     "start_time": "2025-01-03T00:32:15.623166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the unified locations dataframe\n",
    "df_unified_locations"
   ],
   "id": "6a211925bc7b880a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      location_id building_number                street    zip    borough  \\\n",
       "0               1             NaN                   NaN    NaN  Manhattan   \n",
       "1               2             NaN                   NaN    NaN  Manhattan   \n",
       "2               3             NaN                   NaN    NaN  Manhattan   \n",
       "3               4             NaN                   NaN    NaN  Manhattan   \n",
       "4               5             NaN                   NaN    NaN  Manhattan   \n",
       "...           ...             ...                   ...    ...        ...   \n",
       "1228         1228       undefined  343 WEST   46 STREET  10036  Manhattan   \n",
       "1229         1229       undefined       39 ESSEX STREET  10002  Manhattan   \n",
       "1230         1230             64W                  48th  10036  Manhattan   \n",
       "1231         1231       undefined        13351 37TH AVE  11354     Queens   \n",
       "1232         1232       undefined  470 WEST   23 STREET  10011  Manhattan   \n",
       "\n",
       "                                                address  \\\n",
       "0                     E. 5th St. East Village Manhattan   \n",
       "1     New York County Courthouse 40 Foley Square Low...   \n",
       "2     W. 47th St. and Seventh Ave. Times Square Manh...   \n",
       "3     E. 60-66th St. and Madison Ave. Upper East Sid...   \n",
       "4                    World Trade Center Lower Manhattan   \n",
       "...                                                 ...   \n",
       "1228                343 WEST   46 STREET, Manhattan, NY   \n",
       "1229                     39 ESSEX STREET, Manhattan, NY   \n",
       "1230                            64W 48th, Manhattan, NY   \n",
       "1231                         13351 37TH AVE, Queens, NY   \n",
       "1232                470 WEST   23 STREET, Manhattan, NY   \n",
       "\n",
       "                                 address_indicator  \\\n",
       "0                                              N/A   \n",
       "1      New York County Courthouse on Foley Square.   \n",
       "2     47th St. and 7th Ave. Times Square Manhattan   \n",
       "3                              60-66th and Madison   \n",
       "4                               World Trade Center   \n",
       "...                                            ...   \n",
       "1228                                           NaN   \n",
       "1229                                           NaN   \n",
       "1230                                           NaN   \n",
       "1231                                           NaN   \n",
       "1232                                           NaN   \n",
       "\n",
       "                             neighborhood_or_nta            latitude  \\\n",
       "0                                   East Village  40.722445296182798   \n",
       "1                                Lower Manhattan  40.713700000000003   \n",
       "2                                   Times Square  40.759220487652101   \n",
       "3                                Upper East Side  40.766100000000002   \n",
       "4                                Lower Manhattan    40.7117926273691   \n",
       "...                                          ...                 ...   \n",
       "1228                                     Clinton            40.76034   \n",
       "1229                                   Chinatown           40.716135   \n",
       "1230                                         NaN                 NaN   \n",
       "1231                                    Flushing           40.760757   \n",
       "1232  Hudson Yards-Chelsea-Flatiron-Union Square           40.747264   \n",
       "\n",
       "                longitude source_type  \n",
       "0       -73.9786505699157     filming  \n",
       "1     -74.007900000000006     filming  \n",
       "2     -73.984621167182894     filming  \n",
       "3                -73.9696     filming  \n",
       "4     -74.012328386306706     filming  \n",
       "...                   ...         ...  \n",
       "1228           -73.989196  restaurant  \n",
       "1229           -73.989467  restaurant  \n",
       "1230                  NaN  restaurant  \n",
       "1231            -73.83328  restaurant  \n",
       "1232           -74.003176  restaurant  \n",
       "\n",
       "[1233 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>building_number</th>\n",
       "      <th>street</th>\n",
       "      <th>zip</th>\n",
       "      <th>borough</th>\n",
       "      <th>address</th>\n",
       "      <th>address_indicator</th>\n",
       "      <th>neighborhood_or_nta</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>source_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>E. 5th St. East Village Manhattan</td>\n",
       "      <td>N/A</td>\n",
       "      <td>East Village</td>\n",
       "      <td>40.722445296182798</td>\n",
       "      <td>-73.9786505699157</td>\n",
       "      <td>filming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County Courthouse 40 Foley Square Low...</td>\n",
       "      <td>New York County Courthouse on Foley Square.</td>\n",
       "      <td>Lower Manhattan</td>\n",
       "      <td>40.713700000000003</td>\n",
       "      <td>-74.007900000000006</td>\n",
       "      <td>filming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>W. 47th St. and Seventh Ave. Times Square Manh...</td>\n",
       "      <td>47th St. and 7th Ave. Times Square Manhattan</td>\n",
       "      <td>Times Square</td>\n",
       "      <td>40.759220487652101</td>\n",
       "      <td>-73.984621167182894</td>\n",
       "      <td>filming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>E. 60-66th St. and Madison Ave. Upper East Sid...</td>\n",
       "      <td>60-66th and Madison</td>\n",
       "      <td>Upper East Side</td>\n",
       "      <td>40.766100000000002</td>\n",
       "      <td>-73.9696</td>\n",
       "      <td>filming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>World Trade Center Lower Manhattan</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Lower Manhattan</td>\n",
       "      <td>40.7117926273691</td>\n",
       "      <td>-74.012328386306706</td>\n",
       "      <td>filming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1228</td>\n",
       "      <td>undefined</td>\n",
       "      <td>343 WEST   46 STREET</td>\n",
       "      <td>10036</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>343 WEST   46 STREET, Manhattan, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>40.76034</td>\n",
       "      <td>-73.989196</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1229</td>\n",
       "      <td>undefined</td>\n",
       "      <td>39 ESSEX STREET</td>\n",
       "      <td>10002</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>39 ESSEX STREET, Manhattan, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>40.716135</td>\n",
       "      <td>-73.989467</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1230</td>\n",
       "      <td>64W</td>\n",
       "      <td>48th</td>\n",
       "      <td>10036</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>64W 48th, Manhattan, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>undefined</td>\n",
       "      <td>13351 37TH AVE</td>\n",
       "      <td>11354</td>\n",
       "      <td>Queens</td>\n",
       "      <td>13351 37TH AVE, Queens, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flushing</td>\n",
       "      <td>40.760757</td>\n",
       "      <td>-73.83328</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1232</td>\n",
       "      <td>undefined</td>\n",
       "      <td>470 WEST   23 STREET</td>\n",
       "      <td>10011</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>470 WEST   23 STREET, Manhattan, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hudson Yards-Chelsea-Flatiron-Union Square</td>\n",
       "      <td>40.747264</td>\n",
       "      <td>-74.003176</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 463
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:22.984882Z",
     "start_time": "2025-01-03T00:32:22.977412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_missing_ids(source_df, target_df, column_name):\n",
    "    \"\"\"\n",
    "    Check if all values in the specified column of the source DataFrame are present in the target DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        source_df (pd.DataFrame): The DataFrame containing the source column to check.\n",
    "        target_df (pd.DataFrame): The DataFrame where the values should be found.\n",
    "        column_name (str): The name of the column to check.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the result of the check.\n",
    "    \"\"\"\n",
    "    # Find missing IDs\n",
    "    missing_ids = set(source_df[column_name]) - set(target_df[column_name])\n",
    "\n",
    "    # Print results\n",
    "    if missing_ids:\n",
    "        print(f\"Count of missing {column_name}: {len(missing_ids)}\")\n",
    "        print(f\"These {column_name} values are missing: {missing_ids}\")\n",
    "    else:\n",
    "        print(f\"All {column_name} values from the source DataFrame are present in the target DataFrame.\")\n",
    "\n",
    "# Check for missing location IDs in filming locations\n",
    "check_missing_ids(df_locations_m, df_unified_locations, 'location_id')\n",
    "# Check for missing location IDs in restaurant locations\n",
    "check_missing_ids(df_locations_r, df_unified_locations, 'location_id')\n",
    "check_missing_ids(df_restaurants, df_locations_r, 'location_id')\n",
    "\n"
   ],
   "id": "59556a9d1dfa973c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All location_id values from the source DataFrame are present in the target DataFrame.\n",
      "All location_id values from the source DataFrame are present in the target DataFrame.\n",
      "All location_id values from the source DataFrame are present in the target DataFrame.\n"
     ]
    }
   ],
   "execution_count": 464
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:28.444626Z",
     "start_time": "2025-01-03T00:32:28.415081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "geolocator = Nominatim(user_agent=\"food-and-the-city\")\n",
    "\n",
    "def geocode_location(row):\n",
    "    \"\"\"Determine whether to perform reverse or forward geocoding.\"\"\"\n",
    "    if pd.notna(row['latitude']) and pd.notna(row['longitude']):\n",
    "        # Reverse geocoding\n",
    "        result = reverse_geocode_geopy(row['latitude'], row['longitude'])\n",
    "        if result:\n",
    "            return process_geocode_result(row, result, status=\"success\")\n",
    "    elif pd.isna(row['latitude']) or pd.isna(row['longitude']):\n",
    "        # Forward geocoding (try multiple address formats)\n",
    "        address_formats = [\n",
    "            f\"{row['street']} {row['zip']} {row['borough']}\",\n",
    "            f\"{row['building_number']} {row['street']} {row['zip']} {row['borough']}\"\n",
    "        ]\n",
    "        for address in address_formats:\n",
    "            result = forward_geocode_geopy(address)\n",
    "            if result:\n",
    "                return process_geocode_result(row, result, status=\"success\")\n",
    "    # If all geocoding attempts fail\n",
    "    return process_geocode_result(row, None, status=\"failed\")\n",
    "\n",
    "def reverse_geocode_geopy(lat, lon, retries=1, delay=1):\n",
    "    \"\"\"Perform reverse geocoding using Geopy with error handling.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            location = geolocator.reverse((lat, lon), addressdetails=True, timeout=10)\n",
    "            if location:\n",
    "                return location.raw\n",
    "        except (GeocoderTimedOut, GeocoderQuotaExceeded) as e:\n",
    "            print(f\"Error: {e}. Retrying reverse geocode... ({attempt + 1}/{retries})\")\n",
    "        time.sleep(delay * (attempt + 1))\n",
    "    return None\n",
    "\n",
    "def forward_geocode_geopy(address, retries=1, delay=1):\n",
    "    \"\"\"Perform forward geocoding using Geopy with error handling.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            location = geolocator.geocode(address, addressdetails=True, timeout=10)\n",
    "            if location:\n",
    "                return location.raw\n",
    "        except (GeocoderTimedOut, GeocoderQuotaExceeded) as e:\n",
    "            print(f\"Error: {e}. Retrying forward geocode... ({attempt + 1}/{retries})\")\n",
    "        time.sleep(delay * (attempt + 1))\n",
    "    return None\n",
    "\n",
    "def process_geocode_result(row, result, status):\n",
    "    \"\"\"Process the geocoding result and return a standardized dictionary.\"\"\"\n",
    "    if status == \"success\" and result:\n",
    "        address_details = result.get('address', {})\n",
    "        return {\n",
    "            'location_id': row['location_id'],\n",
    "            'source_type': row['source_type'],\n",
    "            'status': status,\n",
    "            'failure_reason': None,\n",
    "            'address_type': result.get('type'),\n",
    "            'name': result.get('name'),\n",
    "            'display_name': result.get('display_name'),\n",
    "            'latitude': result.get('lat'),\n",
    "            'longitude': result.get('lon'),\n",
    "            'house_number': address_details.get('house_number'),\n",
    "            'road': address_details.get('road'),\n",
    "            'neighbourhood': address_details.get('neighbourhood'),\n",
    "            'suburb': address_details.get('suburb'),\n",
    "            'county': address_details.get('county'),\n",
    "            'city': address_details.get('city'),\n",
    "            'state': address_details.get('state'),\n",
    "            'ISO3166-2-lvl4': address_details.get('ISO3166-2-lvl4'),\n",
    "            'postcode': address_details.get('postcode'),\n",
    "            'country': address_details.get('country'),\n",
    "            'country_code': address_details.get('country_code')\n",
    "        }\n",
    "    else:\n",
    "        # Handle failed geocoding\n",
    "        return {\n",
    "            'location_id': row['location_id'],\n",
    "            'source_type': row['source_type'],\n",
    "            'status': status,\n",
    "            'failure_reason': 'No response or invalid data' if status == \"failed\" else None,\n",
    "            'address_type': None,\n",
    "            'name': None,\n",
    "            'display_name': None,\n",
    "            'latitude': row['latitude'],\n",
    "            'longitude': row['longitude'],\n",
    "            'house_number': row.get('building_number'),\n",
    "            'road': row.get('street'),\n",
    "            'neighbourhood': row.get('neighborhood_or_nta'),\n",
    "            'suburb': None,\n",
    "            'county': None,\n",
    "            'city': None,\n",
    "            'state': None,\n",
    "            'ISO3166-2-lvl4': None,\n",
    "            'postcode': row.get('zip'),\n",
    "            'country': None,\n",
    "            'country_code': None\n",
    "        }\n",
    "\n",
    "def process_locations_with_geopy(df):\n",
    "    \"\"\"Process all locations in the DataFrame using Geopy.\"\"\"\n",
    "    results = [geocode_location(row) for _, row in df.iterrows()]\n",
    "    return pd.DataFrame(results)\n"
   ],
   "id": "6642237f517f1440",
   "outputs": [],
   "execution_count": 465
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:23:47.873628Z",
     "start_time": "2025-01-02T19:02:38.633098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process the unified locations DataFrame\n",
    "df_standardized_locations = process_locations_with_geopy(df_unified_locations)"
   ],
   "id": "905933b2cec50218",
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:26:40.588147Z",
     "start_time": "2025-01-02T19:26:40.574864Z"
    }
   },
   "cell_type": "code",
   "source": "df_standardized_locations",
   "id": "f4051cf85a45693a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      location_id source_type   status failure_reason address_type  \\\n",
       "0               1     filming  success           None        house   \n",
       "1               2     filming  success           None          yes   \n",
       "2               3     filming  success           None    secondary   \n",
       "3               4     filming  success           None        house   \n",
       "4               5     filming  success           None     memorial   \n",
       "...           ...         ...      ...            ...          ...   \n",
       "1228         1228  restaurant  success           None          yes   \n",
       "1229         1229  restaurant  success           None          yes   \n",
       "1230         1230  restaurant  success           None  residential   \n",
       "1231         1231  restaurant  success           None          yes   \n",
       "1232         1232  restaurant  success           None          yes   \n",
       "\n",
       "                                         name  \\\n",
       "0                                               \n",
       "1                                               \n",
       "2                                  7th Avenue   \n",
       "3                                               \n",
       "4     National September 11 Memorial & Museum   \n",
       "...                                       ...   \n",
       "1228                                            \n",
       "1229                                            \n",
       "1230                         West 48th Street   \n",
       "1231                                            \n",
       "1232                                            \n",
       "\n",
       "                                           display_name            latitude  \\\n",
       "0     725, East 5th Street, Manhattan Community Boar...          40.7225384   \n",
       "1     9, Murray Street, Lower Manhattan, Manhattan, ...         40.71360755   \n",
       "2     7th Avenue, Manhattan Community Board 5, Manha...   40.75922040082986   \n",
       "3     23, East 63rd Street, Manhattan Community Boar...          40.7662611   \n",
       "4     National September 11 Memorial & Museum, 180, ...  40.711367499999994   \n",
       "...                                                 ...                 ...   \n",
       "1228  332, West 46th Street, Clinton, Manhattan Comm...          40.7601652   \n",
       "1229  39, Essex Street, Manhattan Community Board 3,...  40.716231449999995   \n",
       "1230  West 48th Street, Manhattan Community Board 5,...  40.760574210220845   \n",
       "1231  133-51, 37th Avenue, Flushing Chinatown, Queen...          40.7608996   \n",
       "1232  448, West 23rd Street, Manhattan Community Boa...         40.74703585   \n",
       "\n",
       "               longitude house_number              road  \\\n",
       "0            -73.9786049          725   East 5th Street   \n",
       "1     -74.00786515839098            9     Murray Street   \n",
       "2     -73.98462105157385         None        7th Avenue   \n",
       "3            -73.9697195           23  East 63rd Street   \n",
       "4     -74.01327039290445          180  Greenwich Street   \n",
       "...                  ...          ...               ...   \n",
       "1228  -73.98928033274845          332  West 46th Street   \n",
       "1229  -73.98969329662256           39      Essex Street   \n",
       "1230  -73.98591939580174         None  West 48th Street   \n",
       "1231  -73.83338102509316       133-51       37th Avenue   \n",
       "1232   -74.0033575109756          448  West 23rd Street   \n",
       "\n",
       "                    neighbourhood     suburb           county  \\\n",
       "0     Manhattan Community Board 3  Manhattan  New York County   \n",
       "1                            None  Manhattan  New York County   \n",
       "2     Manhattan Community Board 5  Manhattan  New York County   \n",
       "3     Manhattan Community Board 8  Manhattan  New York County   \n",
       "4                       Whitehall  Manhattan  New York County   \n",
       "...                           ...        ...              ...   \n",
       "1228                      Clinton  Manhattan  New York County   \n",
       "1229  Manhattan Community Board 3  Manhattan  New York County   \n",
       "1230  Manhattan Community Board 5  Manhattan  New York County   \n",
       "1231           Flushing Chinatown     Queens    Queens County   \n",
       "1232  Manhattan Community Board 4  Manhattan  New York County   \n",
       "\n",
       "                  city     state ISO3166-2-lvl4 postcode        country  \\\n",
       "0     City of New York  New York          US-NY    10009  United States   \n",
       "1     City of New York  New York          US-NY    10007  United States   \n",
       "2     City of New York  New York          US-NY    10019  United States   \n",
       "3     City of New York  New York          US-NY    10065  United States   \n",
       "4     City of New York  New York          US-NY    10007  United States   \n",
       "...                ...       ...            ...      ...            ...   \n",
       "1228  City of New York  New York          US-NY    10036  United States   \n",
       "1229  City of New York  New York          US-NY    10002  United States   \n",
       "1230  City of New York  New York          US-NY    10036  United States   \n",
       "1231  City of New York  New York          US-NY    11354  United States   \n",
       "1232  City of New York  New York          US-NY    10011  United States   \n",
       "\n",
       "     country_code  \n",
       "0              us  \n",
       "1              us  \n",
       "2              us  \n",
       "3              us  \n",
       "4              us  \n",
       "...           ...  \n",
       "1228           us  \n",
       "1229           us  \n",
       "1230           us  \n",
       "1231           us  \n",
       "1232           us  \n",
       "\n",
       "[1233 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>source_type</th>\n",
       "      <th>status</th>\n",
       "      <th>failure_reason</th>\n",
       "      <th>address_type</th>\n",
       "      <th>name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>house_number</th>\n",
       "      <th>road</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>suburb</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>ISO3166-2-lvl4</th>\n",
       "      <th>postcode</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>filming</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>house</td>\n",
       "      <td></td>\n",
       "      <td>725, East 5th Street, Manhattan Community Boar...</td>\n",
       "      <td>40.7225384</td>\n",
       "      <td>-73.9786049</td>\n",
       "      <td>725</td>\n",
       "      <td>East 5th Street</td>\n",
       "      <td>Manhattan Community Board 3</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10009</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>filming</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>9, Murray Street, Lower Manhattan, Manhattan, ...</td>\n",
       "      <td>40.71360755</td>\n",
       "      <td>-74.00786515839098</td>\n",
       "      <td>9</td>\n",
       "      <td>Murray Street</td>\n",
       "      <td>None</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10007</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>filming</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>secondary</td>\n",
       "      <td>7th Avenue</td>\n",
       "      <td>7th Avenue, Manhattan Community Board 5, Manha...</td>\n",
       "      <td>40.75922040082986</td>\n",
       "      <td>-73.98462105157385</td>\n",
       "      <td>None</td>\n",
       "      <td>7th Avenue</td>\n",
       "      <td>Manhattan Community Board 5</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10019</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>filming</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>house</td>\n",
       "      <td></td>\n",
       "      <td>23, East 63rd Street, Manhattan Community Boar...</td>\n",
       "      <td>40.7662611</td>\n",
       "      <td>-73.9697195</td>\n",
       "      <td>23</td>\n",
       "      <td>East 63rd Street</td>\n",
       "      <td>Manhattan Community Board 8</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10065</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>filming</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>memorial</td>\n",
       "      <td>National September 11 Memorial &amp; Museum</td>\n",
       "      <td>National September 11 Memorial &amp; Museum, 180, ...</td>\n",
       "      <td>40.711367499999994</td>\n",
       "      <td>-74.01327039290445</td>\n",
       "      <td>180</td>\n",
       "      <td>Greenwich Street</td>\n",
       "      <td>Whitehall</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10007</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1228</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>332, West 46th Street, Clinton, Manhattan Comm...</td>\n",
       "      <td>40.7601652</td>\n",
       "      <td>-73.98928033274845</td>\n",
       "      <td>332</td>\n",
       "      <td>West 46th Street</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10036</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1229</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>39, Essex Street, Manhattan Community Board 3,...</td>\n",
       "      <td>40.716231449999995</td>\n",
       "      <td>-73.98969329662256</td>\n",
       "      <td>39</td>\n",
       "      <td>Essex Street</td>\n",
       "      <td>Manhattan Community Board 3</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10002</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1230</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>residential</td>\n",
       "      <td>West 48th Street</td>\n",
       "      <td>West 48th Street, Manhattan Community Board 5,...</td>\n",
       "      <td>40.760574210220845</td>\n",
       "      <td>-73.98591939580174</td>\n",
       "      <td>None</td>\n",
       "      <td>West 48th Street</td>\n",
       "      <td>Manhattan Community Board 5</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10036</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>133-51, 37th Avenue, Flushing Chinatown, Queen...</td>\n",
       "      <td>40.7608996</td>\n",
       "      <td>-73.83338102509316</td>\n",
       "      <td>133-51</td>\n",
       "      <td>37th Avenue</td>\n",
       "      <td>Flushing Chinatown</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11354</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1232</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>448, West 23rd Street, Manhattan Community Boa...</td>\n",
       "      <td>40.74703585</td>\n",
       "      <td>-74.0033575109756</td>\n",
       "      <td>448</td>\n",
       "      <td>West 23rd Street</td>\n",
       "      <td>Manhattan Community Board 4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>New York County</td>\n",
       "      <td>City of New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>10011</td>\n",
       "      <td>United States</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:36.642457Z",
     "start_time": "2025-01-03T00:32:36.636672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "check_missing_ids(df_unified_locations, df_standardized_locations, 'location_id')\n",
    "# Check for missing location IDs in filming locations\n",
    "check_missing_ids(df_locations_m, df_standardized_locations, 'location_id')\n",
    "# Check for missing location IDs in restaurant locations\n",
    "check_missing_ids(df_locations_r, df_standardized_locations, 'location_id')\n",
    "check_missing_ids(df_restaurants, df_standardized_locations, 'location_id')\n",
    "\n"
   ],
   "id": "641c5075b74141c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All location_id values from the source DataFrame are present in the target DataFrame.\n",
      "All location_id values from the source DataFrame are present in the target DataFrame.\n",
      "All location_id values from the source DataFrame are present in the target DataFrame.\n",
      "All location_id values from the source DataFrame are present in the target DataFrame.\n"
     ]
    }
   ],
   "execution_count": 466
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:40.239952Z",
     "start_time": "2025-01-03T00:32:40.233315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mapping for each table\n",
    "mapping_fc_locations = {\n",
    "    'location_id': 'loc_id',\n",
    "    'source_type': 'loc_source_type',\n",
    "    'status': 'loc_status',\n",
    "    'failure_reason': 'loc_failure_reason',\n",
    "    'address_type': 'loc_address_type',\n",
    "    'name': 'loc_name',\n",
    "    'display_name': 'loc_display_name',\n",
    "    'latitude': 'loc_latitude',\n",
    "    'longitude': 'loc_longitude',\n",
    "    'house_number': 'loc_house_number',\n",
    "    'road': 'loc_road',\n",
    "    'neighbourhood': 'loc_neighborhood',\n",
    "    'suburb': 'loc_suburb',\n",
    "    'county': 'loc_county',\n",
    "    'city': 'loc_city',\n",
    "    'state': 'loc_state',\n",
    "    'ISO3166-2-lvl4': 'loc_iso3166_2_lvl4',\n",
    "    'postcode': 'loc_postcode',\n",
    "    'country': 'loc_country',\n",
    "    'country_code': 'loc_country_code',\n",
    "}\n",
    "\n",
    "mapping_fc_filming_locations = {\n",
    "    'location_id': 'fl_location_id',\n",
    "    'imdb_id': 'fl_imdb_id',\n",
    "}\n",
    "\n",
    "mapping_fc_restaurants = {\n",
    "    'restaurant_id': 'res_id',\n",
    "    'restaurant_name': 'res_name',\n",
    "    'legal_business_name': 'res_legal_business_name',\n",
    "    'doing_business_as_dba': 'res_doing_business_as_dba',\n",
    "    'seating_interest_sidewalk': 'res_seating_interest_sidewalk',\n",
    "    'landmarkdistrict_terms': 'res_landmarkdistrict_terms',\n",
    "    'location_id': 'res_location_id',\n",
    "}\n",
    "\n",
    "mapping_fc_actors = {\n",
    "    'actor_id': 'act_id',\n",
    "    'actor_name': 'act_name',\n",
    "}\n",
    "\n",
    "mapping_fc_genre = {\n",
    "    'genre_id': 'gen_id',\n",
    "    'genre': 'gen_name',\n",
    "}\n",
    "\n",
    "mapping_fc_genres_movies = {\n",
    "    'genre_id': 'gm_genre_id',\n",
    "    'imdb_id': 'gm_imdb_id',\n",
    "}\n",
    "\n",
    "mapping_fc_actors_movies = {\n",
    "    'actor_id': 'am_actor_id',\n",
    "    'imdb_id': 'am_imdb_id',\n",
    "}\n",
    "\n",
    "mapping_fc_movies = {\n",
    "    'imdb_id': 'mov_imdb_id',\n",
    "    'title': 'mov_title',\n",
    "    'year': 'mov_year',\n",
    "    'director': 'mov_director',\n",
    "    'writer': 'mov_writer',\n",
    "    'overview': 'mov_overview',\n",
    "    'rating': 'mov_rating',\n",
    "    'nb_users_ratings': 'mov_nb_users_ratings',\n",
    "}\n",
    "\n"
   ],
   "id": "538af796a9a1fc17",
   "outputs": [],
   "execution_count": 467
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:32:44.478969Z",
     "start_time": "2025-01-03T00:32:44.474766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rename_columns(df, column_mapping):\n",
    "    \"\"\"\n",
    "    Rename DataFrame columns using a mapping dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to rename.\n",
    "        column_mapping (dict): A dictionary mapping old column names to new ones.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with renamed columns.\n",
    "    \"\"\"\n",
    "    return df.rename(columns=column_mapping)\n"
   ],
   "id": "eeb5efd20ee6ad6d",
   "outputs": [],
   "execution_count": 468
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:49:07.689299Z",
     "start_time": "2025-01-03T00:49:07.673510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rename columns for fc_locations\n",
    "df_locations_renamed = rename_columns(df_standardized_locations, mapping_fc_locations)\n",
    "\n",
    "# Rename columns for fc_filming_locations\n",
    "df_filming_locations_renamed = rename_columns(df_locations_movies, mapping_fc_filming_locations)\n",
    "\n",
    "# Rename columns for fc_restaurants\n",
    "df_restaurants_renamed = rename_columns(df_restaurants, mapping_fc_restaurants)\n",
    "\n",
    "# Rename columns for fc_actors\n",
    "df_actors_renamed = rename_columns(df_actors, mapping_fc_actors)\n",
    "\n",
    "# Rename columns for fc_genre\n",
    "df_genres_renamed = rename_columns(df_genres, mapping_fc_genre)\n",
    "\n",
    "# Rename columns for fc_genres_movies\n",
    "df_movies_genres_renamed = rename_columns(df_movies_genres, mapping_fc_genres_movies)\n",
    "\n",
    "# Rename columns for fc_actors_movies\n",
    "df_movies_actors_renamed = rename_columns(df_movies_actors, mapping_fc_actors_movies)\n",
    "\n",
    "# Rename columns for fc_movies\n",
    "df_movies_cleaned_renamed = rename_columns(df_movies_cleaned, mapping_fc_movies)\n",
    "\n"
   ],
   "id": "8a474ce2a1fcc6c3",
   "outputs": [],
   "execution_count": 502
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:37:22.144548Z",
     "start_time": "2025-01-03T00:37:22.137919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the database connection parameters\n",
    "DATABASE_CONFIG = {\n",
    "    'user': 'root',\n",
    "    'password': 'root',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'food-and-the-city'\n",
    "}\n",
    "\n",
    "# Create the database connection URL\n",
    "DATABASE_URL = f\"postgresql://{DATABASE_CONFIG['user']}:{DATABASE_CONFIG['password']}@\" \\\n",
    "               f\"{DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}\"\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(DATABASE_URL)"
   ],
   "id": "2b838c50470bdabb",
   "outputs": [],
   "execution_count": 481
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:37:25.011430Z",
     "start_time": "2025-01-03T00:37:25.004400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy.exc import IntegrityError\n",
    "\n",
    "def load_dataframe_to_postgres(df, table_name, engine, if_exists='append', primary_key_column=None):\n",
    "    \"\"\"\n",
    "    Load a pandas DataFrame into a PostgreSQL database, logging errors and continuing processing.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to load.\n",
    "        table_name (str): The target table name.\n",
    "        engine: The SQLAlchemy database engine.\n",
    "        if_exists (str): Behavior when the table exists. Options: 'fail', 'replace', 'append'.\n",
    "        primary_key_column (str): The name of the primary key column to log failing rows.\n",
    "    \"\"\"\n",
    "    if primary_key_column and primary_key_column not in df.columns:\n",
    "        raise ValueError(f\"Primary key column '{primary_key_column}' not found in the DataFrame.\")\n",
    "\n",
    "    successful_rows = []\n",
    "    failed_rows = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Insert each row individually\n",
    "            row_df = pd.DataFrame([row])\n",
    "            row_df.to_sql(table_name, engine, index=False, if_exists=if_exists, method=\"multi\")\n",
    "            successful_rows.append(row[primary_key_column] if primary_key_column else index)\n",
    "        except IntegrityError as e:\n",
    "            engine.dispose()  # Dispose the engine to avoid locked connections\n",
    "            #print(f\"IntegrityError: {e}\")\n",
    "            failed_rows.append({\n",
    "                \"row\": row.to_dict(),\n",
    "                \"primary_key\": row[primary_key_column] if primary_key_column else index,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            continue\n",
    "\n",
    "    # Log the results\n",
    "    print(f\"Successfully inserted rows: {len(successful_rows)}\")\n",
    "    print(f\"Failed rows: {len(failed_rows)}\")\n",
    "    #if failed_rows:\n",
    "    #    for failed_row in failed_rows:\n",
    "    #        print(f\"Failed primary key: {failed_row['primary_key']}, Error: {failed_row['error']}\")\n",
    "\n",
    "    return successful_rows, failed_rows\n",
    "\n"
   ],
   "id": "6f82f65f55a462d5",
   "outputs": [],
   "execution_count": 482
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:44:37.267020Z",
     "start_time": "2025-01-03T00:38:00.225774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load movies\n",
    "print(\"Loading movies...\")\n",
    "successful_movies, failed_movies = load_dataframe_to_postgres(df_movies_cleaned_renamed,'fc_movies',engine,primary_key_column='mov_imdb_id')"
   ],
   "id": "14dd192d5f8a3cfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movies...\n",
      "Successfully inserted rows: 23922\n",
      "Failed rows: 480\n"
     ]
    }
   ],
   "execution_count": 483
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:44:42.999052Z",
     "start_time": "2025-01-03T00:44:42.990322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataframe_to_postgres_batch(df, table_name, engine, if_exists='append', batch_size=1000):\n",
    "    \"\"\"\n",
    "    Load a pandas DataFrame into a PostgreSQL database, logging and returning failed batches.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to load.\n",
    "        table_name (str): The target table name.\n",
    "        engine: The SQLAlchemy database engine.\n",
    "        if_exists (str): Behavior when the table exists. Options: 'fail', 'replace', 'append'.\n",
    "        batch_size (int): The number of rows to insert in each batch.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (successful_rows, failed_batches)\n",
    "    \"\"\"\n",
    "    successful_rows = 0\n",
    "    failed_batches = []\n",
    "\n",
    "    # Divide the DataFrame into batches\n",
    "    batches = [df[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "    for i, batch in enumerate(batches):\n",
    "        try:\n",
    "            # Batch insert using to_sql\n",
    "            batch.to_sql(\n",
    "                table_name,\n",
    "                engine,\n",
    "                index=False,\n",
    "                if_exists=if_exists,\n",
    "                method=\"multi\"  # Use the \"multi\" method for batch inserts\n",
    "            )\n",
    "            successful_rows += len(batch)\n",
    "        except IntegrityError as e:\n",
    "            engine.dispose()  # Dispose of the engine to avoid locked connections\n",
    "            #print(f\"Error during batch {i}: {e}\")\n",
    "            failed_batches.append({\"batch_index\": i, \"rows\": batch, \"error\": str(e)})\n",
    "\n",
    "    # Log the results\n",
    "    print(f\"Successfully inserted rows: {successful_rows}\")\n",
    "    print(f\"Failed batches: {len(failed_batches)}\")\n",
    "\n",
    "    return successful_rows, failed_batches\n"
   ],
   "id": "c7fbbefc733faabf",
   "outputs": [],
   "execution_count": 488
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:44:46.437616Z",
     "start_time": "2025-01-03T00:44:46.429150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reprocess_failed_batches(failed_batches, table_name, engine):\n",
    "    \"\"\"\n",
    "    Reprocess rows from failed batches by inserting them individually into the database.\n",
    "\n",
    "    Parameters:\n",
    "        failed_batches (list): A list of dictionaries containing failed batch details.\n",
    "        table_name (str): The target table name.\n",
    "        engine: The SQLAlchemy database engine.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (successful_rows, retry_failed_rows)\n",
    "    \"\"\"\n",
    "    successful_rows = 0\n",
    "    retry_failed_rows = []\n",
    "\n",
    "    for failed_batch in failed_batches:\n",
    "        batch_index = failed_batch[\"batch_index\"]\n",
    "        batch_rows = failed_batch[\"rows\"]\n",
    "\n",
    "        print(f\"Retrying rows from failed batch {batch_index} individually...\")\n",
    "        for _, row in batch_rows.iterrows():\n",
    "            try:\n",
    "                # Insert each row individually\n",
    "                row_df = pd.DataFrame([row])\n",
    "                row_df.to_sql(\n",
    "                    table_name,\n",
    "                    engine,\n",
    "                    index=False,\n",
    "                    if_exists='append',\n",
    "                    method=\"multi\"\n",
    "                )\n",
    "                successful_rows += 1\n",
    "            except IntegrityError as e:\n",
    "                retry_failed_rows.append({\n",
    "                    \"row\": row.to_dict(),\n",
    "                    \"batch_index\": batch_index,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                print(f\"Error inserting row in batch {batch_index}: {e}\")\n",
    "\n",
    "    # Log the results\n",
    "    print(f\"Successfully reprocessed rows: {successful_rows}\")\n",
    "    print(f\"Failed rows after retry: {len(retry_failed_rows)}\")\n",
    "\n",
    "    return successful_rows, retry_failed_rows\n"
   ],
   "id": "ee7033b9d0c0e449",
   "outputs": [],
   "execution_count": 489
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:44:50.468313Z",
     "start_time": "2025-01-03T00:44:50.460805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of renamed DataFrames and their descriptions\n",
    "dataframes = {\n",
    "    \"fc_locations\": df_locations_renamed,\n",
    "    \"fc_filming_locations\": df_filming_locations_renamed,\n",
    "    \"fc_restaurants\": df_restaurants_renamed,\n",
    "    \"fc_actors\": df_actors_renamed,\n",
    "    \"fc_genres\": df_genres_renamed,\n",
    "    \"fc_genres_movies\": df_movies_genres_renamed,\n",
    "    \"fc_actors_movies\": df_movies_actors_renamed,\n",
    "    \"fc_movies\": df_movies_cleaned_renamed,\n",
    "}\n",
    "\n",
    "# Iterate over the DataFrames and print the number of rows\n",
    "for name, dataframe in dataframes.items():\n",
    "    print(f\"Number of rows in {name}: {len(dataframe)}\")\n"
   ],
   "id": "7e0252005ec06bcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in fc_locations: 1233\n",
      "Number of rows in fc_filming_locations: 233\n",
      "Number of rows in fc_restaurants: 1000\n",
      "Number of rows in fc_actors: 51729\n",
      "Number of rows in fc_genres: 24\n",
      "Number of rows in fc_genres_movies: 60353\n",
      "Number of rows in fc_actors_movies: 24402\n",
      "Number of rows in fc_movies: 24402\n"
     ]
    }
   ],
   "execution_count": 490
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:50:26.663884Z",
     "start_time": "2025-01-03T00:50:26.483823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the DataFrames into the database\n",
    "# Load locations\n",
    "#print(\"Loading locations...\")\n",
    "#successful_locations, failed_locations = load_dataframe_to_postgres_batch(df_locations_renamed,'fc_locations',engine,batch_size=50)\n",
    "\n",
    "# Load restaurants\n",
    "#print(\"Loading restaurants...\")\n",
    "#successful_restaurants, failed_restaurants = load_dataframe_to_postgres_batch(df_restaurants_renamed,'fc_restaurants',engine,batch_size=20)\n",
    "\n",
    "# Load movies\n",
    "#print(\"Loading movies...\")\n",
    "#successful_movies, failed_movies = load_dataframe_to_postgres_batch(df_movies_cleaned_renamed,'fc_movies',engine,batch_size=1000)\n",
    "\n",
    "# Load genres\n",
    "#print(\"Loading Genres...\")\n",
    "#successful_genres, failed_genres = load_dataframe_to_postgres_batch(df_genres_renamed,'fc_genres',engine,batch_size=5)\n",
    "\n",
    "# Load actors\n",
    "#print(\"Loading Actors...\")\n",
    "#successful_actors, failed_actors = load_dataframe_to_postgres_batch(df_actors_renamed,'fc_actors',engine,batch_size=5000)\n",
    "\n",
    "#print(\"Loading Movies-Genres...\")\n",
    "#successful_genres_movies, failed_genres_movies = load_dataframe_to_postgres_batch(df_movies_genres_renamed, 'fc_genres_movies', engine, batch_size=5000)\n",
    "\n",
    "#print(\"Loading Movies-Actors...\")\n",
    "#successful_movies_actors, failed_movies_actors = load_dataframe_to_postgres_batch(df_movies_actors_renamed, 'fc_actors_movies', engine, batch_size=10000)\n",
    "\n",
    "print(\"Loading Filming Locations...\")\n",
    "successful_filming_locations, failed_filming_locations = load_dataframe_to_postgres_batch(df_filming_locations_renamed, 'fc_filming_locations', engine, batch_size=50)"
   ],
   "id": "967456d312ee3ef0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Filming Locations...\n",
      "Successfully inserted rows: 200\n",
      "Failed batches: 1\n"
     ]
    }
   ],
   "execution_count": 505
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:50:26.791279Z",
     "start_time": "2025-01-03T00:50:26.780622Z"
    }
   },
   "cell_type": "code",
   "source": "df_filming_locations_renamed",
   "id": "ae8878c3b2227936",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fl_location_id fl_imdb_id\n",
       "0                 1  tt0092494\n",
       "1                 2  tt0050083\n",
       "2                 3  tt0337563\n",
       "3                 4  tt0179626\n",
       "4                 5  tt0307901\n",
       "..              ...        ...\n",
       "228             229  tt0096463\n",
       "229             230  tt0061209\n",
       "230             231  tt0061209\n",
       "231             232  tt0128853\n",
       "232             233  tt0128853\n",
       "\n",
       "[233 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_location_id</th>\n",
       "      <th>fl_imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0092494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0050083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0337563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0179626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>tt0307901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>tt0096463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>230</td>\n",
       "      <td>tt0061209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>231</td>\n",
       "      <td>tt0061209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>232</td>\n",
       "      <td>tt0128853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>233</td>\n",
       "      <td>tt0128853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 506
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Summary Logs\n",
    "print(f\"Locations: {len(successful_locations)} inserted, {len(failed_locations)} failed\")\n",
    "print(f\"Restaurants: {len(successful_restaurants)} inserted, {len(failed_restaurants)} failed\")\n",
    "print(f\"Movies: {len(successful_movies)} inserted, {len(failed_movies)} failed\")\n",
    "print(f\"Genres: {len(successful_genres)} inserted, {len(failed_genres)} failed\")\n",
    "print(f\"Actors: {len(successful_actors)} inserted, {len(failed_actors)} failed\")"
   ],
   "id": "4fd92ba2e5276308"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:50:57.706334Z",
     "start_time": "2025-01-03T00:50:57.701123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect failed batches (if any)\n",
    "if failed_filming_locations:\n",
    "    print(f\"Number of failed batches: {len(failed_filming_locations)}\")\n",
    "    for failed_batch in failed_filming_locations:\n",
    "        #print(f\"Failed batch index: {failed_batch['batch_index']}, Error: {failed_batch['error']}\")\n",
    "        # Display only the first element of each key/value pair\n",
    "        first_batch_index = str(failed_batch['batch_index'])[0]\n",
    "        first_error_char = str(failed_batch['error'])[5]\n",
    "        print(f\"Failed batch index: {first_batch_index}, Error: {first_error_char}\")\n",
    "\n"
   ],
   "id": "c64af5636275a750",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failed batches: 1\n",
      "Failed batch index: 4, Error: o\n"
     ]
    }
   ],
   "execution_count": 507
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T00:51:30.105279Z",
     "start_time": "2025-01-03T00:51:29.758043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reprocess failed batches later\n",
    "if failed_filming_locations:\n",
    "        reprocess_successful, retry_failed_rows = reprocess_failed_batches(failed_filming_locations, \"fc_filming_locations\", engine)\n"
   ],
   "id": "d274f92d33d0c224",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying rows from failed batch 4 individually...\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(201) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 201, 'fl_imdb_id_m0': 'tt0265666'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(202) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 202, 'fl_imdb_id_m0': 'tt0048605'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(203) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 203, 'fl_imdb_id_m0': 'tt0133952'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(204) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 204, 'fl_imdb_id_m0': 'tt0141842'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(205) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 205, 'fl_imdb_id_m0': 'tt0367089'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(206) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 206, 'fl_imdb_id_m0': 'tt0072251'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(207) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 207, 'fl_imdb_id_m0': 'tt0080120'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(208) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 208, 'fl_imdb_id_m0': 'tt0080120'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(209) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 209, 'fl_imdb_id_m0': 'tt0078504'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(210) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 210, 'fl_imdb_id_m0': 'tt0051207'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(211) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 211, 'fl_imdb_id_m0': 'tt0073802'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(212) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 212, 'fl_imdb_id_m0': 'tt0081635'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(213) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 213, 'fl_imdb_id_m0': 'tt0084805'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(214) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 214, 'fl_imdb_id_m0': 'tt0056626'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(215) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 215, 'fl_imdb_id_m0': 'tt0062425'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(216) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 216, 'fl_imdb_id_m0': 'tt0069449'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(217) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 217, 'fl_imdb_id_m0': 'tt0069449'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(218) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 218, 'fl_imdb_id_m0': 'tt0263757'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(219) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 219, 'fl_imdb_id_m0': 'tt0259711'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(220) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 220, 'fl_imdb_id_m0': 'tt0094291'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(221) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 221, 'fl_imdb_id_m0': 'tt0094291'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(222) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 222, 'fl_imdb_id_m0': 'tt0055614'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(223) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 223, 'fl_imdb_id_m0': 'tt0055614'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(224) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 224, 'fl_imdb_id_m0': 'tt0098635'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(225) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 225, 'fl_imdb_id_m0': 'tt0098635'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(226) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 226, 'fl_imdb_id_m0': 'tt0083336'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(227) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 227, 'fl_imdb_id_m0': 'tt0083336'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(228) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 228, 'fl_imdb_id_m0': 'tt0083336'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(229) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 229, 'fl_imdb_id_m0': 'tt0096463'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(230) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 230, 'fl_imdb_id_m0': 'tt0061209'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(231) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 231, 'fl_imdb_id_m0': 'tt0061209'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(232) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 232, 'fl_imdb_id_m0': 'tt0128853'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error inserting row in batch 4: (psycopg2.errors.ForeignKeyViolation) insert or update on table \"fc_filming_locations\" violates foreign key constraint \"fc_filming_locations_fl_location_id_fkey\"\n",
      "DETAIL:  Key (fl_location_id)=(233) is not present in table \"fc_locations\".\n",
      "\n",
      "[SQL: INSERT INTO fc_filming_locations (fl_location_id, fl_imdb_id) VALUES (%(fl_location_id_m0)s, %(fl_imdb_id_m0)s)]\n",
      "[parameters: {'fl_location_id_m0': 233, 'fl_imdb_id_m0': 'tt0128853'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Successfully reprocessed rows: 0\n",
      "Failed rows after retry: 33\n"
     ]
    }
   ],
   "execution_count": 508
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO Clean duplicates on movies tables before inserting them\n",
    "# TODO Solve the batch issue on the movies tables"
   ],
   "id": "b4c1f1f1e109c17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
